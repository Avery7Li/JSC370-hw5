---
title: "JSC370 Assignment 04 - HPC and ML 2"
author: "Zhengdan Li"
date: "18/03/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports, include=FALSE}
library(matrixStats)
library(parallel)
library(foreach)
library(doParallel)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(randomForest)
library(gbm)
library(xgboost)
library(caret)
library(data.table)
library(kableExtra)
```

# HPC
## Problem 1: Make sure your code is nice
Rewrite the following R functions to make them faster.

```{r}
# Total row sums
fun1 <- function(mat) { 
  n <- nrow(mat)
  ans <- double(n)
  for (i in 1:n) {
    ans[i] <- sum(mat[i, ])
  }
  ans 
}

fun1alt <- function(mat) { 
  # YOUR CODE HERE
  ans <- rowSums(mat)
  ans
}

# Cumulative sum by row
fun2 <- function(mat) { 
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) { 
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1] 
    }
  }
  ans 
}

fun2alt <- function(mat) { 
  # YOUR CODE HERE
  #ans <- t(apply(t(mat), 2, cumsum))  # mean time 1.197601: 1
  #ans <- t(apply(mat, 1, cumsum))
  ans <- rowCumsums(mat)  #library(matrixStats)
  ans 
}

# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
options(microbenchmark.unit="relative")
microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), check = "equivalent"#, unit = "relative"
)

# Test for the second
microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), check = "equivalent"
)
```


For fun1, the original mean runtime is around 1.8 times the runtime of the optimized version. For fun2, when I used the external function rowCumsums from the matrixStats library, the mean runtime improved from over 10x to 1x.

## Problem 2: Make things run faster with parallel computing
The following function allows simulating PI.

```{r}
sim_pi <- function(n = 1000, i = NULL) { 
  p <- matrix(runif(n*2), ncol = 2) 
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156) 
sim_pi(1000) # 3.132
```

In order to get accurate estimates, I ran this function multiple times, with the following code:

```{r}
# This runs the simulation a 4,000 times, each with 10,000 points
set.seed(1231) 

system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans)) 
})
```

Rewrite the previous code using parLapply() to make it run faster. Make sure you set the seed using clusterSetRNGStream():

```{r}
# YOUR CODE HERE
system.time({
  # YOUR CODE HERE
  ncpus <- 2L
  n <- 10000
  # Create parallel sockets
  cl <- makePSOCKcluster(ncpus)
  # Set seed
  clusterSetRNGStream(cl, 370)
  clusterExport(cl, varlist = c("n"), envir = environment())
  # Simulate for 4000 times using parLapply
  ans <- unlist(parLapply(cl, seq_len(4000), sim_pi))
  print(mean(ans))
  # YOUR CODE HERE
  stopCluster(cl)
})
```

We can see that the elapsed time decreased from around 10 to 2.

# ML

I loaded the data for 332 major league baseball players into a data table. I will use different methods to predict players' salaries based on the features in the dataset. 

To later performed boosting, I first converted character variables, `League`, `NewLeague`, and `Division`, into numeric variables and filtered out missing values. Then, I split the data into training and testing sets (70%,30%) using sampled indices.

```{r load data, include=FALSE}
hitters <- read.csv("https://raw.githubusercontent.com/JSC370/jsc370-2022/main/data/hitters/hitters.csv")
```

```{r wrangling, include=FALSE}
hitters$League <- ifelse(hitters$League == "A", 1, 0)  # Unique values A & N
hitters$NewLeague <- ifelse(hitters$NewLeague == "A", 1, 0)
hitters$Division <- ifelse(hitters$Division == "E", 1, 0)  # Unique values E & W
hitters <-na.omit(hitters)

set.seed(1234)
# Update train and test set as I dropped some rows
train_idx <- sample(seq_len(nrow(hitters)), round(nrow(hitters)*0.7))
train <- hitters[train_idx,] 
test <- hitters[-train_idx,]
```

## 1. Regression Tree

I fitted a regression tree for the salary using the ANOVA method since salary has continous values. The complexity parameter was initially set to 0 to later explore the optimal value and trim the tree. The plot of the result tree is as follows.

```{r fit tree}
hitter_tree <- rpart(Salary~., data=train, method="anova", 
                     control=list(minsplit=10, 
                                  minbucket=3, cp=0, xval=10))
rpart.plot(hitter_tree)
```

Then I pruned the tree using the complexity parameter which yields the minimum xerror. The pruned tree was visualized below.

```{r, eval=TRUE, echo=TRUE, warning=FALSE}
plotcp(hitter_tree)
# with the minimum xerror
optimalcp <-hitter_tree$cptable[which.min(hitter_tree$cptable[, 'xerror']), 'CP'] 

hitter_tree_prune<-prune(hitter_tree, cp=optimalcp)
rpart.plot(hitter_tree_prune)
```

```{r tree predict, include=FALSE}
tree_pred <- predict(hitter_tree_prune, test)
confmatrix_table <- table(true=test$Salary, tree_pred = tree_pred)
```


## 2. Bagging

I next used bagging to predict `Salary`. The parameter `mtry` in the randomForest function was set to 19, which equals the number of features in the hitters dataset. Other parameters were kept as default. The variable importance plot was generated using ``varImpPlot``. It is noticeable from the plot that CHits, CRBI, and CRuns have the highest importance values.

```{r bagging}
hitter_bag <- randomForest(Salary~., data=train, mtry=19, na.action=na.omit)
# Importance plot
varImpPlot(hitter_bag, n.var=19, col="red", main="Bagging Variable Importance Plot")
```

## 3. Random Forest

For random forests, I used the function ``randomForest`` with all default parameters. The variable importances are displayed in the following plot. Similar with the bagging result, CHits, CRBI, and CRuns have the highest importance values.

```{r forest}
hitter_rf <- randomForest(Salary~., data=train, na.action=na.omit)
varImpPlot(hitter_rf, n.var=19, col="green", main="Random Forest Variable Importance Plot")
```


## 4. Boosting

I performed boosting with 1000 trees using a range of values of the shrinkage parameter $\lambda$ 0.1, 0.01, and 0.001. Since the salary has continuous values, I specified the distribution to be "gaussian". For each shrinkage parameter, I recorded the training set MSE to later generate a plot of MSE with respect to shrinkage parameter.

```{r}
par(mfrow=c(3,2))
lambda_list <- list(0.001, 0.01, 0.1)
# Initialize result list
train_mse_list <- rep(0, 3)   
test_mse_list <- rep(0, 3)   

# Loop over lambda values and perform boosting
for (i in 1:length(lambda_list)) {
  hitter_boost = gbm(Salary~., data=train, distribution="gaussian", 
                     n.trees=1000, shrinkage=lambda_list[[i]], 
                     interaction.depth = 2, cv.folds=5)
  # Predict on train set data
  yhat_boost_train <- predict(hitter_boost, newdata=train, n.trees=1000)
  # Calculate MSE
  train_mse_list[i] <- mean((yhat_boost_train-train[, "Salary"])^2)
  yhat_boost_test <- predict(hitter_boost, newdata=test, n.trees=1000)
  test_mse_list[i] <- mean((yhat_boost_test-test[, "Salary"])^2)
}
```

From the plot of MSE against shrinkage parameter below, it is noticeable that the training set mean squared error has the lowest value with the shrinkage parameter of 0.1. However, when it comes to the MSE on the testing set, shrinkage parameter 0.001 yields the smallest error. I'll use the model with 0.001 shrinkage parameter for constructing the variable importance plot and later calculating the test MSE. 

```{r boosting mse plot, echo=FALSE}
boost_mse_dt <- data.frame(MSE = c(train_mse_list, test_mse_list),
                           Set = c(rep("Training Set", 3), 
                                     rep("Test Set", 3)),
                           `Shrinkage Parameter` = 
                             c(0.001, 0.01, 0.1, 0.001, 0.01, 0.1))
boost_mse_dt %>% ggplot(aes(x=`Shrinkage.Parameter`, y=MSE, colour=Set)) + 
  geom_line() +geom_point() +
  labs(title="MSE with Shrinkage Parameter")
  
#plot(lambda_list, train_mse_list, type="b", main="Training Set Mean Squared Error 
#     with Various Shrinkage Parameter Values", 
#     xlab="Shrinkage Parameter", ylab="MSE", color="red")
#lines(lambda_list, test_mse_list, type="b")
#axis(1, at=1:10, labels=letters[1:10])
```

```{r}
# Use lambda = 0.01
hitter_boost = gbm(Salary~., data=train, distribution="gaussian", n.trees=1000, 
                   shrinkage=0.001, interaction.depth = 2, cv.folds=5)
summary(hitter_boost)
```

Similar to the results from bagging and random forest, variables CHits, CRuns, and CRBI from boosting have the largest importance values.  

## 5. XGBoost

```{r xgb, message=FALSE, warning=FALSE}
train_control = trainControl(method="cv", number=10, search="grid")
tune_grid <- expand.grid(max_depth= c(1, 3, 5, 7),
                         nrounds = (1:10) *50,
                         eta = c(0.01, 0.1, 0.3),  # learning rate
                         gamma = 0,
                         subsample = 1,
                         min_child_weight = 1,
                         colsample_bytree = 0.6 # number of columns that get subsampled
                         )

hitter_xgb <- caret::train(Salary~., data=train, method="xgbTree", 
                           trControl = train_control, tuneGrid = tune_grid,
                           verbosity = 0)
```

```{r, echo=FALSE}
plot(varImp(hitter_xgb, scale=F), main="XGBoost Variable Importance")
```

The result of XGBoost is slightly different from that of previous models, the variables of the largest importance is CHits, CRBI, and AtBat instead of CRuns.

## 6. Mean Squared Error

As a last step, I computed the MSE values on test sets for each method. The results are summarized in the table below.

```{r MSE}
# Regression tree
yhat_tree <- predict(hitter_tree_prune, test)
tree_mse <- mean((yhat_tree-test[, "Salary"])^2)

# Bagging
yhat_bag <- predict(hitter_bag, newdata=test)
bag_mse <- mean((yhat_bag-test[, "Salary"])^2)

# Random forest
yhat_rf <- predict(hitter_rf, newdata=test)
rf_mse <- mean((yhat_rf - test[, "Salary"])^2)

# Boosting 
yhat_boost_test <- predict(hitter_boost, newdata=test, n.trees=1000)
boost_mse <- mean((yhat_boost_test-test[, "Salary"])^2)

# XGBoost
yhat_xgb <- predict(hitter_xgb, newdata=test)
xgb_mse <- mean((yhat_xgb-test[, "Salary"])^2)

mse_dt <- data.table(Method = c("Regression Tree", "Bagging", "Random Forest",
                                "Boosting", "XGBoost"),
                     MSE = c(tree_mse, bag_mse, rf_mse, boost_mse, xgb_mse))
mse_dt <- mse_dt[order(MSE)]
mse_dt %>%
  kbl(caption = "Test MSE for Methods") %>%
  kable_styling("striped", full_width=FALSE)

mse_dt %>%
  ggplot(aes(reorder(Method, MSE), MSE)) + 
  geom_bar(stat = 'identity') +
  coord_flip() +
  labs(x="Method", y="MSE", title="Barplot of MSE for Methods")
```

From the table, it is noticeable that boosting yields the smallest test MSE. Bagging and random forest have similar and slightly larger error rate. On the other hand, regression tree and XGBoost yield the largest errors.
